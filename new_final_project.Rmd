---
title: "New_final_project"
author: "Haokun Zhang, Zhang Lu, Jonathan"
date: "2023-04-21"
output:
  pdf_document: default
  md_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# Workflow
# 1. Define the question:  How much should we pay for Audit fee?
# 2. Data wrangling
# 3. Data Visualization(EDA - Exploratory Data Analysis) 
# 4. Unsupervised learning: Clustering
# 5. Supervised learning: choose the model(Supervised learning): 
#     Linear regression, knn, Regression tree: random forest, CART, Boosting & Lasso regression
# 6. Model training: Split to Training set & Testing set,  do the K-fold Cross-Validation
# 7. Assess the model performance: k-fold cv, MSE, R-square, F-1 score(the chart of actual and  predicted)
# Choose the best performance model，use it to do the prediction，並且將結果圖表化？ Partial dependence plots etc)
### 8. Conclusion: What did we learn- 根據不同的input value, 可以預測audit fee為多少
```

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# loaded the needed packages and read the data
library(ggplot2)
library(caret)
library(car)
library(factoextra)
library(randomForest)
library(rfUtilities)
library(rsample)
library(multcomp) 
library(cluster) 

df <- read.csv("https://raw.githubusercontent.com/haokunz/Data_mining_project/main/data/internal_controls_data_0421.csv",
               header = TRUE)

```



```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# Step 2. Data wrangling
# delete copyright and lines of notes
df <- df[-c(nrow(df), nrow(df)-1), ]

# remove records with restated internal control report
duplicated_indexes <- which(df$Restated.Internal.Control.Report == "Yes (1)")
duplicated_companies <- unique(df$Company[duplicated_indexes])
restate_indexes <- which(df$Company %in% duplicated_companies)
remove_index <- setdiff(restate_indexes, duplicated_indexes)
df1 <- df[-remove_index, ]

# remove duplicated records from different auditors working at the same time
multi_auditors <- table(df1$Company)[table(df1$Company) >= 2]
remove_index_2 <- setdiff(which(df1$Company %in% names(multi_auditors)), match(names(multi_auditors), df1$Company))
df2 <- df1[-remove_index_2, ]

# remove rows with missing revenue data
df2 <- df2[df2$Revenue.... != "", ]

# select target columns
df3 <- df2[ ,c("Company", "City", "State.Code", "State.Name", "State.Region", 
               "Auditor", "Auditor.Key", "Auditor.State.Name", 
               "Effective.Internal.Controls", "Audit.Fees....", "Non.Audit.Fees....",
               "Total.Fees....", "Share.Price", "Market.Cap....", "Revenue....",
               "Earnings....", "Book.Value....", "Assets....")]

# change column names to mark the targets
colnames(df3) <- c("company", "city", "state_code", "state_name", "state_region",
                   "auditor", "auditor_key", "auditor_state_name", 
                   "effective_internal_controls", "audit_fees", "non_audit_fees",
                   "total_fees", "share_price", "market_cap","revenue",
                   "earnings", "book_value", "assets")

# convert money amount character into numeric
df3$audit_fees = as.numeric(gsub(",", "", df3$audit_fees))
df3$non_audit_fees = as.numeric(gsub(",", "", df3$non_audit_fees))
df3$total_fees = as.numeric(gsub(",", "", df3$total_fees))
df3$market_cap = as.numeric(gsub(",", "", df3$market_cap))
df3$revenue = as.numeric(gsub(",", "", df3$revenue))
df3$earnings = as.numeric(gsub(",", "", df3$earnings))
df3$book_value = as.numeric(gsub(",", "", df3$book_value))
df3$assets = as.numeric(gsub(",", "", df3$assets))

# add indicator for analysis
df3$big_four_indicator <- ifelse(df3$auditor_key <= 4, 1, 0)
df3$five_category <- ifelse(df3$auditor_key < 5, df3$auditor_key, 5)
df3$audit_percent <- df3$audit_fees / df3$total_fees

# add transformation variables to the data
df3$audit_fees_bc <- predict(BoxCoxTrans(df3$audit_fees), df3$audit_fees)
non_audit_bc <- predict(BoxCoxTrans(df3$non_audit_fees[df3$non_audit_fees!=0]),
                        df3$non_audit_fees[df3$non_audit_fees!=0])
df3$total_fees_bc <- predict(BoxCoxTrans(df3$total_fees), df3$total_fees)
df3$market_cap_bc <- predict(BoxCoxTrans(df3$market_cap), df3$market_cap)
df3$market_fee_ratio <- log(df3$market_cap/ df3$total_fees)
df3$assets_log <- log(df3$assets)

revenue_0 = jitter(df3$revenue)
df3$revenue_trans <- (revenue_0/abs(revenue_0)) * log(abs(df3$revenue) + 1)

earnings_0 = jitter(df3$earnings)
df3$earnings_trans <- (earnings_0/abs(earnings_0)) * log(abs(df3$earnings) + 1)

# change columns to factors
df3$big_4_factor <- as.factor(df3$big_four_indicator)
df3$five_category_factor <- as.factor(df3$five_category)
df3$state_region <- as.factor(df3$state_region)




```

# Data visualization(EDA)
Plot 1: plot the number distribution of companies in different regions
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# Step 3. Data Visualization(EDA - Exploratory Data Analysis) 
# basic plots, preliminary exploration #
# plot the number distribution of companies in different regions
company_numbers <- sort(table(df3$state_region[df3$state_region != ""]), decreasing = FALSE, na.last = NA)

par(mar = c(5.1, 6.5, 4.1, 2.1))
barplot(height=company_numbers,
        names.arg=c("Canada", "US_NewEng", "US_Southwest", "US_Southeast",
                    "US_Midwest", "Foreign", "US_MAtlan", "US_West"),
        col="#69b3a2", horiz=TRUE, las = 1, main = "Num. of Companies", xlab = "numbers")
par(mar = c(5.1, 4.1, 4.1, 2.1))

```

Plot 2: Use eight plots to display the effect of transformation on fee related variables
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# use eight plots to display the effect of transformation on fee related variables
par(mfrow = c(2, 4))
hist(df3$audit_fees, breaks="Scott", main="audit fees", xlab="Audit fees")
hist(df3$audit_fees_bc, main="audit fees (transformed)", xlab="Audit fees")
hist(df3$non_audit_fees, breaks="Scott", main="non audit fees", xlab="Non-audit fees")
hist(non_audit_bc, main="non audit fees (transformed)", xlab="Non-audit fees")
hist(df3$total_fees, breaks="Scott", main="total fees", xlab="Total fees")
hist(df3$total_fees_bc, main="total fees (transformed)", xlab="Total fees")
hist(df3$market_cap, breaks="Scott", main="Market cap", xlab="Market cap")
hist(df3$market_cap_bc, main="Market cap (transformed)", xlab="Market cap")
par(mfrow = c(1, 1))




```

Plot 3: Use three plots to display the categorical data
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# use three plots to display the categorical data
par(mfrow = c(1, 3))
barplot(table(df3$five_category_factor), ylab = "Frequency", main="Auditing company distribution")
barplot(table(df3$big_4_factor), yaxt='n', ylab="Frequency", main="Num. big4 vs. other")
axis(side=2, at=seq(0, nrow(df3), 200))
barplot(table(df3$effective_internal_controls), yaxt='n', ylab="Frequency", main="Num. effective internal controls")
axis(side=2, at=seq(0, nrow(df3), 200))
par(mfrow = c(1, 1))


```

Plot 4. Plot the transformed company market cap, total auditing fees, and effective internal control
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# plot the transformed company market cap, total auditing fees, and effective internal control
sp = ggplot(df3, aes(x=market_cap_bc, y=five_category_factor,
                     group=effective_internal_controls)) +
     geom_point(aes(color=effective_internal_controls), size=0.9,
                    position=position_dodge2(0.3))

labels = as.vector(outer(rep("Num. of 'No'="), table(df3$effective_internal_controls,
                                           df3$five_category_factor)[1,],
                         paste, sep=""))
sp + annotate(geom="text", x=rep(27.5, 5), y=seq(0.7, 4.7, 1), label= labels) 

```

Plot 5: Plot the transformed company market cap vs. total auditing fees
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# plot the transformed company market cap vs. total auditing fees
ggplot(df3, aes(x=market_cap_bc, y=total_fees_bc, group=five_category_factor)) +
  geom_point(aes(color=five_category_factor), size=0.9)

cor(df3$market_cap_bc, df3$total_fees_bc)

```

Plot 6: Plot the auditing fees
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# plot the auditing fees
ggplot(df3, aes(x=five_category_factor, y=total_fees_bc)) + 
  geom_violin(trim=FALSE, fill="gray")+
  labs(title="Auditing fees",x="category", y = "total fees")+
  geom_boxplot(width=0.3)+
  theme_classic()
# Change color by groups
dp <- ggplot(df3, aes(x=five_category_factor, y=total_fees_bc, fill=five_category_factor)) + 
  geom_violin(trim=FALSE)+
  geom_boxplot(width=0.3, fill="white")+
  labs(title="Plot of auditing fees",x="category", y = "total fees")
dp + theme_classic()

```


# Perform a statistical test here to compare big4 vs non big4 when considering
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# perform a statistical test here to compare big4 vs non big4 when considering
# market cap as covariate 

# perform analysis of variance for 1-5 auditing company levels(ANOVA)
m5_ancova = lm(total_fees_bc ~ five_category_factor + market_cap_bc +
              five_category_factor*market_cap_bc, df3)
Anova(m5_ancova, type=3)

multi_comarisons <- lm(total_fees_bc ~ five_category_factor + market_cap_bc, df3)
postHocs <- glht(multi_comarisons, linfct=mcp(five_category_factor="Tukey")) # generalize linear hypothesis test
summary(postHocs)
plot(postHocs)

```

# Unsupervised learning: Clustering
Find the optimal number of clustering
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
set.seed(143) # same random values are produced each time you run the code
pca_data = na.omit(df3[ ,c("audit_fees_bc", "total_fees_bc", "market_cap_bc",
                           "market_fee_ratio", "assets_log", "revenue_trans",
                           "earnings_trans")])

gap_stat <- clusGap(pca_data, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)
print(gap_stat, method = "firstmax")
fviz_gap_stat(gap_stat)

```
The optimal number of clusters is 2

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
km.res <- kmeans(pca_data, 2, nstart=25) # k-means clustering

aggregate(pca_data, by=list(cluster=km.res$cluster), mean) # get the summary statistics of the data by group.

dd <- cbind(pca_data, cluster=km.res$cluster)
head(dd)
fviz_cluster(km.res, data=pca_data)

```
The above: How to explain it 

# Supervised Learning
In the supervised learning part, we want to build several models and choose the best performance model to do the prediction of total audit fees. The workflow is shown below:
Firstly, We want to try various models. We chose 5 models here: Linear model, KNN model,Random forest model, CART model and Gradient-Boosting model. 
Secondly, we used K-fold cross validation to assess the model.
Lastly, we would consider the MAE, RMSE and R-square to decide which model has the best performance.
In the first step, we did the preliminary feature engineering, we abandon some features.
#####說明為什麼只選擇這幾個variable去做mdoel: ask Luna#####

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# The preliminary feature engineering: Abandon some unimportant features
tc <- trainControl(method="cv", number=5)

lmtotal_cv <- train(total_fees_bc ~ five_category_factor + earnings_trans + state_region + effective_internal_controls + audit_fees_bc + share_price + market_cap_bc + revenue_trans +
                 assets_log , data=df3, na.action=na.omit,
               method="lm", trControl=tc)

knntotal_cv <- train(total_fees_bc ~ five_category_factor + earnings_trans + state_region + effective_internal_controls + audit_fees_bc + share_price + market_cap_bc + revenue_trans +
                 assets_log, data=df3, na.action=na.omit,
                method="knn", trControl=tc, tuneLength=20)

rftotal_cv <- train(total_fees_bc ~  five_category_factor + earnings_trans + state_region + effective_internal_controls + audit_fees_bc + share_price + market_cap_bc + revenue_trans +
                 assets_log, data=df3,na.action=na.omit,
               method="rf", trControl=tc, tuneLength=10 )

carttotal_cv <- train(total_fees_bc ~  five_category_factor + earnings_trans + state_region + effective_internal_controls + audit_fees_bc + share_price + market_cap_bc + revenue_trans +
                 assets_log, data=df3,na.action=na.omit,
                 method="rpart", trControl=tc, tuneLength=10)

gbmtotal_cv <- train(total_fees_bc ~  five_category_factor + earnings_trans + state_region + effective_internal_controls + audit_fees_bc + share_price + market_cap_bc + revenue_trans +
                 assets_log, data=df3,na.action=na.omit,
                method="gbm", trControl=tc, tuneLength=10, verbose=FALSE)

model_list_total <- list(lm = lmtotal_cv, knn = knntotal_cv, rf = rftotal_cv, cart = carttotal_cv, gbm = gbmtotal_cv)
res_total = resamples(model_list_total) # rsample: take randomly drawn (sub)samples of the sample and calculate the statistic from that (sub)sample
summary(res_total)

## THe feature variables name
# five_category_factor
# earnings_trans
# state_region
# effective_internal_controls # effective_internal_controls沒有轉成 factor
# audit_fees_bc
# share_price
# market_cap_bc
# revenue_trans
# assets_log


```
From the above figures, we. can see that linear model has the lowest MAE, Random Forest has the second lowest MAE. Gradient-Boosting model has the lowest RMSWE, and Random Forest also has the. second lowest RMSE.As a result, we decided to choose these 3 models initially and do the advanced feature engineering.
###老師有教怎麼用stepwise model 找出feature selection###
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# Step 6 & 7: Model training and assess the model performance

# compare models with 5-fold cross-validation
## Model building and use k-fold cv(k =5)
tc <- trainControl(method="cv", number=5)
lm_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
                 market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
               method="lm", trControl=tc)

# knn_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
#                   market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
#                 method="knn", trControl=tc, tuneLength=20)

rf_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
                 market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
               method="rf", trControl=tc, tuneLength=10)

# cart_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
#                    market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
#                  method="rpart", trControl=tc, tuneLength=10)

gbm_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
                  market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
                method="gbm", trControl=tc, tuneLength=10, verbose=FALSE)

# Assess the model performance
model_list <- list(lm = lm_cv, knn = knn_cv, rf = rf_cv, cart = cart_cv, gbm = gbm_cv)
res = resamples(model_list) # rsample: take randomly drawn (sub)samples of the sample and calculate the statistic from that (sub)sample
summary(res) # the higher is R-square is better

```
Depend on the above figures, after the advanced feature engineering, we saw that random forest model has the best performance, which has the lowest MAE, lowest RMSE and highest R-square. 

So we chose Random Forest model to do the prediction of total auditing fee based on other variables.
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# Choose the best performance model，use it to do the prediction
# predict the total auditing fee based on other variables
set.seed(2501)
data_split = initial_split(df3, prop=0.8)
data_train = training(data_split)
data_test = testing(data_split)

rf1 <- randomForest(total_fees_bc ~ five_category_factor + state_region + 
                      market_cap_bc + assets_log + revenue_trans + earnings_trans,
                    data=data_train, importance=TRUE)

rf1
plot(rf1) 
## From the above chart, we saw that when number of trees is equal to 200, the MSE is slowing down.
## As a result, we decided to choose ntree = 200

rf1_200 <- randomForest(total_fees_bc ~ five_category_factor + state_region + 
                      market_cap_bc + assets_log + revenue_trans + earnings_trans,
                    data=data_train, ntree = 200,  importance=TRUE)
modelr::rmse(rf1_200, data_test)
varImpPlot(rf1_200, type = 1)
# modelr::rmse(rf1, data_test)
# varImpPlot(rf1, type=1) ###%IncMSE(Mean Decrease Accuracy)可以得知去除這項解釋變數(X)的話，模型的準確率會減少幾%。
rf_predict <- predict(rf1_200, data_test)

RSQUARE = function(y_actual,y_predict){
  cor(y_actual,y_predict)^2
}

R2 <- RSQUARE(data_test$audit_fees_bc, rf_predict)

# rf1_200 <- randomForest(total_fees_bc ~ five_category_factor + state_region + 
#                       market_cap_bc + assets_log + revenue_trans + earnings_trans,ntree = 200,
#                     data=data_train, importance=TRUE)
# modelr::rmse(rf1_200, data_test)
# varImpPlot(rf1_200, type=1)
```
The plot of rf1 shows out-of-bag MSE as a function of the number of trees used, We saw that when the number of tree is equal to about 200, the MSE is slowing down. So we choose number of tree = 200.

The explanation of RMSE: Then we saw the RMSE of random forest model is 0.5354485, which is lower than other models.
The explanation of varImpPlot(rf1, type=1):These are the most influential variables of total audit fees.  Revenues has the most influence on the total audit fees as we expected, if we delete the revenue variable, the accuracy of model will decrease about 45%. The other 5 variables: the region of the company, the market cap of the company, the asset of the company, the earnings of the company and whether the company is audited by the big 4, also have major influence on the model.

?????? How to explain why these 6 factors have major influence???????
?????????要不要解釋為什麼只選了這6個變數去做回歸????????
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}

# plot predicted vs. actual values
plot(x=rf_predict, y= data_test$audit_fees_bc, xlab="Predicted Values",
     ylab="Actual Values", main="Predicted vs. Actual Values")

abline(a=0, b=1)
mylabel =  bquote(italic(R)^2 == .(format(R2, digits = 3)))
legend("topleft", legend=mylabel)
```
From the above figure of predict value v.s. actual value, we saw that our model has good performance. The R-square is 0.748, which means that about 75% of the variability observed in the total audit fee can be explained by the random forest model.
However, we know that we can't just use R-square to assess the model performance. We also consider MAE and RMSE. Compare to other models, random forest model still has lowest MAE(the average absolute magnitude between the actual values and the predicted values) and RMSE(the average difference between values predicted by a model and the actual values). As a result, we can make sure that random forest model is the best performance model.



```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
### Neglect below
### Model3: build the best model - feature engineering by LASSO 
# Use LASSO to find main effects + interaction by eyeballing
df3_lasso_x_main = model.matrix(total_fees ~  (.-1-), data=hotels_dev_train)
hotels_lasso_x_itac = model.matrix(children ~  (.-1-arrival_date)^2, data=hotels_dev_train)
hotels_lasso_y = hotels_dev_train$children
## "$" extract a specific part of a data object
```

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}

```

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}

```

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}

```


```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}

```

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}

```
